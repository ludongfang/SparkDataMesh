spark {
  appName = "SparkDataFlow"
  master = "local[*]"
  
  configs {
    "spark.sql.adaptive.enabled" = "true"
    "spark.sql.adaptive.coalescePartitions.enabled" = "true"
    "spark.sql.adaptive.skewJoin.enabled" = "true"
    "spark.serializer" = "org.apache.spark.serializer.KryoSerializer"
    "spark.sql.warehouse.dir" = "/tmp/spark-warehouse"
    "spark.sql.execution.arrow.pyspark.enabled" = "true"
    "spark.sql.parquet.compression.codec" = "snappy"
  }
}

data {
  defaultPath = "/tmp/sparkdataflow"
}

validation {
  enabled = true
}

execution {
  maxRetries = 3
  timeoutMs = 300000
}

logging {
  level = "INFO"
}